{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15493,"status":"ok","timestamp":1704349451988,"user":{"displayName":"인공저지능","userId":"17810132175284132476"},"user_tz":-540},"id":"khYjN8uPk0Uk","outputId":"14622828-6fd8-415f-cf14-3666591fdd9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["\"\"\"from google.colab import drive\n","drive.mount('/content/drive')\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":541,"status":"ok","timestamp":1704425718732,"user":{"displayName":"인공저지능","userId":"17810132175284132476"},"user_tz":-540},"id":"355EP0SdlPOL","outputId":"ffc58304-9706-4cd9-a2df-6c9b4c3a1307"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}],"source":["%cd \"/content/drive/MyDrive\""]},{"cell_type":"code","source":["pip install tensorflow-addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Epuf6pYCrM6","executionInfo":{"status":"ok","timestamp":1704425726264,"user_tz":-540,"elapsed":6980,"user":{"displayName":"인공저지능","userId":"17810132175284132476"}},"outputId":"3be7a835-d77b-404b-98eb-ab0c173cae69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/611.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m522.2/611.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow-addons\n","Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3913,"status":"ok","timestamp":1704425730174,"user":{"displayName":"인공저지능","userId":"17810132175284132476"},"user_tz":-540},"id":"rN0lhve_kWip","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8428b10c-4597-4e8d-9025-b79b9fb3eac5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import os\n","import glob\n","import pandas as pd\n","import tensorflow as tf\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","import tensorflow_addons as tfa\n","\n","from PIL import Image, ImageDraw\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, BatchNormalization\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.metrics import Precision, Recall, AUC\n","from tensorflow.keras.losses import BinaryCrossentropy\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeQLxZ7PlqkA","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1704370384072,"user_tz":-540,"elapsed":409,"user":{"displayName":"인공저지능","userId":"17810132175284132476"}},"outputId":"9e46e7ec-8d32-4ed9-ccf2-d428a3330693"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nbase_folder = 'colab/data/test/dog'\\nclass_folders = os.listdir(base_folder)\\n\\nimage_paths = []\\njson_paths = []\\n\\nfor class_folder in class_folders:\\n    image_files = glob.glob(os.path.join(base_folder, class_folder, '*.jpg'))\\n    json_files = [file.replace('.jpg', '.json') for file in image_files]\\n\\n    image_paths.extend(image_files)\\n    json_paths.extend(json_files)\\n\\nimage_paths = [path.replace('\\\\', '/') for path in image_paths]\\njson_paths = [path.replace('\\\\', '/') for path in json_paths]\\n\\ndf = pd.DataFrame({\\n    'image_path': image_paths,\\n    'json_path': json_paths,\\n    'label': [path.split('/')[-2] for path in image_paths]\\n})\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["\"\"\"\n","base_folder = 'colab/data/test/dog'\n","class_folders = os.listdir(base_folder)\n","\n","image_paths = []\n","json_paths = []\n","\n","for class_folder in class_folders:\n","    image_files = glob.glob(os.path.join(base_folder, class_folder, '*.jpg'))\n","    json_files = [file.replace('.jpg', '.json') for file in image_files]\n","\n","    image_paths.extend(image_files)\n","    json_paths.extend(json_files)\n","\n","image_paths = [path.replace('\\\\', '/') for path in image_paths]\n","json_paths = [path.replace('\\\\', '/') for path in json_paths]\n","\n","df = pd.DataFrame({\n","    'image_path': image_paths,\n","    'json_path': json_paths,\n","    'label': [path.split('/')[-2] for path in image_paths]\n","})\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJitLX_Hnmhw","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1704370385193,"user_tz":-540,"elapsed":4,"user":{"displayName":"인공저지능","userId":"17810132175284132476"}},"outputId":"0aee4791-83f1-4e0f-fc1d-29f946fa0053"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"df.to_csv('colab/csv/df.csv', encoding='utf-8-sig', index=False)\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"source":["\"\"\"df.to_csv('colab/csv/df.csv', encoding='utf-8-sig', index=False)\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82XzaVYULxwI"},"outputs":[],"source":["df = pd.read_csv(\"colab/csv/df.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snL8Ww6IlxFt"},"outputs":[],"source":["def create_mask(image_path, json_path):\n","    try:\n","        with Image.open(image_path) as img:\n","            original_size = img.size\n","            img = img.resize((256, 256))\n","            image = np.array(img, dtype=np.float32)\n","\n","        with open(json_path, 'r', encoding='UTF-8') as file:\n","            data = json.load(file)\n","\n","        mask = Image.new('L', original_size, 0)\n","        draw = ImageDraw.Draw(mask)\n","\n","        for annotation in data['labelingInfo']:\n","            if 'polygon' in annotation:\n","                polygon = []\n","                for i in range(1, len(annotation['polygon']['location'][0]) // 2 + 1):\n","                    x_key = f'x{i}'\n","                    y_key = f'y{i}'\n","                    x = annotation['polygon']['location'][0].get(x_key)\n","                    y = annotation['polygon']['location'][0].get(y_key)\n","                    if x is not None and y is not None:\n","                        polygon.append((x, y))\n","\n","                if polygon:\n","                    draw.polygon(polygon, outline=1, fill=1)\n","\n","        mask = mask.resize((256, 256))\n","        mask = np.array(mask, dtype=np.float32)\n","        mask = np.expand_dims(mask, axis=-1)\n","\n","        return image, mask\n","    except Exception as e:\n","        empty_image = np.zeros((256, 256, 3), dtype=np.float32)\n","        empty_mask = np.zeros((256, 256, 1), dtype=np.float32)\n","        return empty_image, empty_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFRRDEOplxKF"},"outputs":[],"source":["def rotate_image_and_mask(image, mask, angle):\n","    image = tfa.image.rotate(image, angle)\n","    mask = tfa.image.rotate(mask, angle)\n","    return image, mask\n","\n","def tf_create_mask(image_path, json_path):\n","    [image, mask] = tf.numpy_function(create_mask, [image_path, json_path], [tf.float32, tf.float32])\n","    image.set_shape([256, 256, 3])\n","    mask.set_shape([256, 256, 1])\n","    return image, mask\n","\n","image_paths = df['image_path'].values\n","json_paths = df['json_path'].values\n","\n","original_dataset = tf.data.Dataset.from_tensor_slices((image_paths, json_paths))\n","original_dataset = original_dataset.map(tf_create_mask, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","\n","augmented_datasets = []\n","for angle in [0, np.pi/2, np.pi, 3*np.pi/2]:  # 0, 90, 180, 270도\n","    augmented_dataset = original_dataset.map(lambda x, y: rotate_image_and_mask(x, y, angle),\n","                                             num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","    augmented_datasets.append(augmented_dataset)\n","\n","# 모든 데이터셋을 결합합니다.\n","dataset = augmented_datasets[0]\n","for augmented_dataset in augmented_datasets[1:]:\n","    dataset = dataset.concatenate(augmented_dataset)\n","\n","dataset_size = len(image_paths)\n","train_size = int(0.8 * dataset_size)\n","val_size = dataset_size - train_size\n","batch_size = 4\n","\n","dataset = dataset.shuffle(buffer_size=12000).cache().repeat()\n","train_dataset = dataset.take(train_size)\n","val_dataset = dataset.skip(train_size)\n","\n","train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","train_dataset = train_dataset.batch(batch_size)\n","val_dataset = val_dataset.batch(batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"czsAGKmjHyHt"},"outputs":[],"source":["def unet_model(input_size=(256, 256, 3),dropout_rate=0.5):\n","    inputs = Input(input_size)\n","\n","    # 인코더\n","    conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = Conv2D(32, 3, activation='relu', padding='same')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    pool1 = Dropout(dropout_rate)(pool1)\n","\n","    conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(64, 3, activation='relu', padding='same')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    pool2 = Dropout(dropout_rate)(pool2)\n","\n","    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(128, 3, activation='relu', padding='same')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    pool3 = Dropout(dropout_rate)(pool3)\n","\n","    conv4 = Conv2D(256, 3, activation='relu', padding='same')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(256, 3, activation='relu', padding='same')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","    pool4 = Dropout(dropout_rate)(pool4)\n","\n","    conv5 = Conv2D(512, 3, activation='relu', padding='same')(pool4)\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Conv2D(512, 3, activation='relu', padding='same')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","\n","    # 디코더\n","    up6 = UpSampling2D(size=(2, 2))(conv5)\n","    merge6 = concatenate([conv4, up6], axis=3)\n","    conv6 = Conv2D(256, 3, activation='relu', padding='same')(merge6)\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = Conv2D(256, 3, activation='relu', padding='same')(conv6)\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = Dropout(dropout_rate)(conv6)\n","\n","    up7 = UpSampling2D(size=(2, 2))(conv6)\n","    merge7 = concatenate([conv3, up7], axis=3)\n","    conv7 = Conv2D(128, 3, activation='relu', padding='same')(merge7)\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = Conv2D(128, 3, activation='relu', padding='same')(conv7)\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = Dropout(dropout_rate)(conv7)\n","\n","    up8 = UpSampling2D(size=(2, 2))(conv7)\n","    merge8 = concatenate([conv2, up8], axis=3)\n","    conv8 = Conv2D(64, 3, activation='relu', padding='same')(merge8)\n","    conv8 = BatchNormalization()(conv8)\n","    conv8 = Conv2D(64, 3, activation='relu', padding='same')(conv8)\n","    conv8 = BatchNormalization()(conv8)\n","    conv8 = Dropout(dropout_rate)(conv8)\n","\n","    up9 = UpSampling2D(size=(2, 2))(conv8)\n","    merge9 = concatenate([conv1, up9], axis=3)\n","    conv9 = Conv2D(32, 3, activation='relu', padding='same')(merge9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = Conv2D(32, 3, activation='relu', padding='same')(conv9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = Dropout(dropout_rate)(conv9)\n","\n","    # 출력\n","    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n","\n","    model = Model(inputs=inputs, outputs=conv10)\n","\n","    return model\n","\n","class_weight = {0: 1, 1: 40}\n","\n","unet = unet_model()\n","unet.compile(optimizer='adam',\n","             loss=BinaryCrossentropy(from_logits=False),\n","             metrics=['accuracy', Precision(), Recall(), AUC()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qX6yh944lxPj"},"outputs":[],"source":["early_stopping = EarlyStopping(monitor='val_loss',\n","                               patience=10,\n","                               verbose=1,\n","                               mode='min',\n","                               restore_best_weights=True)\n","\n","checkpoint = ModelCheckpoint('colab/model/dog_unet_model_{epoch:02d}.h5',\n","                             monitor='val_loss',\n","                             verbose=1,\n","                             save_best_only=False,\n","                             mode='min',\n","                             save_freq='epoch')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4IS7D1lXoeDF","outputId":"829a4601-197f-4abd-9780-663863cccf49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.6510 - accuracy: 0.8466 - precision: 0.0630 - recall: 0.6371 - auc: 0.8481\n","Epoch 1: saving model to colab/model/dog_unet_model_01.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 4816s 1s/step - loss: 0.6510 - accuracy: 0.8466 - precision: 0.0630 - recall: 0.6371 - auc: 0.8481 - val_loss: 0.2443 - val_accuracy: 0.8915 - val_precision: 0.0803 - val_recall: 0.5840 - val_auc: 0.8698\n","Epoch 2/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.5971 - accuracy: 0.8574 - precision: 0.0722 - recall: 0.6819 - auc: 0.8741\n","Epoch 2: saving model to colab/model/dog_unet_model_02.h5\n","3000/3000 [==============================] - 858s 249ms/step - loss: 0.5971 - accuracy: 0.8574 - precision: 0.0722 - recall: 0.6819 - auc: 0.8741 - val_loss: 1.1198 - val_accuracy: 0.3648 - val_precision: 0.0223 - val_recall: 0.9834 - val_auc: 0.8448\n","Epoch 3/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.5826 - accuracy: 0.8606 - precision: 0.0741 - recall: 0.6896 - auc: 0.8800\n","Epoch 3: saving model to colab/model/dog_unet_model_03.h5\n","3000/3000 [==============================] - 845s 246ms/step - loss: 0.5826 - accuracy: 0.8606 - precision: 0.0741 - recall: 0.6896 - auc: 0.8800 - val_loss: 0.2495 - val_accuracy: 0.8835 - val_precision: 0.0523 - val_recall: 0.3925 - val_auc: 0.7638\n","Epoch 4/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.5723 - accuracy: 0.8601 - precision: 0.0738 - recall: 0.6968 - auc: 0.8828\n","Epoch 4: saving model to colab/model/dog_unet_model_04.h5\n","3000/3000 [==============================] - 855s 249ms/step - loss: 0.5723 - accuracy: 0.8601 - precision: 0.0738 - recall: 0.6968 - auc: 0.8828 - val_loss: 0.2920 - val_accuracy: 0.8573 - val_precision: 0.0650 - val_recall: 0.6489 - val_auc: 0.8621\n","Epoch 5/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.5773 - accuracy: 0.8580 - precision: 0.0753 - recall: 0.7060 - auc: 0.8838\n","Epoch 5: saving model to colab/model/dog_unet_model_05.h5\n","3000/3000 [==============================] - 849s 247ms/step - loss: 0.5773 - accuracy: 0.8580 - precision: 0.0753 - recall: 0.7060 - auc: 0.8838 - val_loss: 0.1015 - val_accuracy: 0.9699 - val_precision: 0.1204 - val_recall: 0.1614 - val_auc: 0.8107\n","Epoch 6/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.5537 - accuracy: 0.8642 - precision: 0.0766 - recall: 0.7065 - auc: 0.8905\n","Epoch 6: saving model to colab/model/dog_unet_model_06.h5\n","3000/3000 [==============================] - 851s 248ms/step - loss: 0.5537 - accuracy: 0.8642 - precision: 0.0766 - recall: 0.7065 - auc: 0.8905 - val_loss: 0.1915 - val_accuracy: 0.9160 - val_precision: 0.0918 - val_recall: 0.5225 - val_auc: 0.8780\n","Epoch 7/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.8649 - precision: 0.0785 - recall: 0.7170 - auc: 0.8941\n","Epoch 7: saving model to colab/model/dog_unet_model_07.h5\n","3000/3000 [==============================] - 838s 244ms/step - loss: 0.5472 - accuracy: 0.8649 - precision: 0.0785 - recall: 0.7170 - auc: 0.8941 - val_loss: 0.2315 - val_accuracy: 0.8846 - val_precision: 0.0810 - val_recall: 0.6628 - val_auc: 0.8958\n","Epoch 8/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.5423 - accuracy: 0.8641 - precision: 0.0794 - recall: 0.7281 - auc: 0.8967\n","Epoch 8: saving model to colab/model/dog_unet_model_08.h5\n","3000/3000 [==============================] - 839s 244ms/step - loss: 0.5423 - accuracy: 0.8641 - precision: 0.0794 - recall: 0.7281 - auc: 0.8967 - val_loss: 0.2722 - val_accuracy: 0.8802 - val_precision: 0.0827 - val_recall: 0.6902 - val_auc: 0.9012\n","Epoch 9/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.5311 - accuracy: 0.8680 - precision: 0.0814 - recall: 0.7315 - auc: 0.9005\n","Epoch 9: saving model to colab/model/dog_unet_model_09.h5\n","3000/3000 [==============================] - 847s 247ms/step - loss: 0.5311 - accuracy: 0.8680 - precision: 0.0814 - recall: 0.7315 - auc: 0.9005 - val_loss: 0.2437 - val_accuracy: 0.9015 - val_precision: 0.0880 - val_recall: 0.5774 - val_auc: 0.8842\n","Epoch 10/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.8694 - precision: 0.0821 - recall: 0.7314 - auc: 0.9012\n","Epoch 10: saving model to colab/model/dog_unet_model_10.h5\n","3000/3000 [==============================] - 845s 246ms/step - loss: 0.5299 - accuracy: 0.8694 - precision: 0.0821 - recall: 0.7314 - auc: 0.9012 - val_loss: 0.4002 - val_accuracy: 0.7761 - val_precision: 0.0556 - val_recall: 0.8678 - val_auc: 0.8986\n","Epoch 11/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.8658 - precision: 0.0834 - recall: 0.7452 - auc: 0.9036\n","Epoch 11: saving model to colab/model/dog_unet_model_11.h5\n","3000/3000 [==============================] - 847s 247ms/step - loss: 0.5302 - accuracy: 0.8658 - precision: 0.0834 - recall: 0.7452 - auc: 0.9036 - val_loss: 0.2479 - val_accuracy: 0.8650 - val_precision: 0.0818 - val_recall: 0.7517 - val_auc: 0.9059\n","Epoch 12/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.5165 - accuracy: 0.8693 - precision: 0.0826 - recall: 0.7429 - auc: 0.9054\n","Epoch 12: saving model to colab/model/dog_unet_model_12.h5\n","3000/3000 [==============================] - 858s 250ms/step - loss: 0.5165 - accuracy: 0.8693 - precision: 0.0826 - recall: 0.7429 - auc: 0.9054 - val_loss: 0.2708 - val_accuracy: 0.8676 - val_precision: 0.0758 - val_recall: 0.7107 - val_auc: 0.8968\n","Epoch 13/30\n","3000/3000 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.9137 - precision: 0.0761 - recall: 0.7048 - auc: 0.9276"]}],"source":["history = unet.fit(train_dataset, epochs=30, steps_per_epoch=train_size // batch_size,\n","                   validation_data=val_dataset, validation_steps=val_size // batch_size,\n","                   class_weight=class_weight,\n","                   callbacks=[checkpoint, early_stopping],\n","                   verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FHSwVUptlxUi"},"outputs":[],"source":["plt.figure(figsize=(18, 5))\n","\n","# 훈련 및 검증 손실 그래프\n","plt.subplot(1, 5, 1)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# 훈련 및 검증 정확도 그래프\n","plt.subplot(1, 5, 2)\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","# 훈련 및 검증 정밀도 그래프\n","plt.subplot(1, 5, 3)\n","plt.plot(history.history['precision_1'], label='Training Precision')\n","plt.plot(history.history['val_precision_1'], label='Validation Precision')\n","plt.title('Training and Validation Precision')\n","plt.xlabel('Epoch')\n","plt.ylabel('Precision')\n","plt.legend()\n","\n","# 훈련 및 검증 재현율 그래프\n","plt.subplot(1, 5, 4)\n","plt.plot(history.history['recall_1'], label='Training Recall')\n","plt.plot(history.history['val_recall_1'], label='Validation Recall')\n","plt.title('Training and Validation Recall')\n","plt.xlabel('Epoch')\n","plt.ylabel('Recall')\n","plt.legend()\n","\n","plt.subplot(1, 5, 5)\n","plt.plot(history.history['auc_1'], label='Training AUC')\n","plt.plot(history.history['val_auc_1'], label='Validation AUC')\n","plt.title('Training and Validation AUC')\n","plt.xlabel('Epoch')\n","plt.ylabel('AUC')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6AscDIyXlxk-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zj0-5iTlxnd"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100","mount_file_id":"1dFdQ86L_xZbFYvEZAjhAxYmEQxyzj8IH","authorship_tag":"ABX9TyOF/55kvGLivAOQSN2GOA5g"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}