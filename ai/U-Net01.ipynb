{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1dFdQ86L_xZbFYvEZAjhAxYmEQxyzj8IH","authorship_tag":"ABX9TyOCu9/7flWD3qnJrmn39aoE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khYjN8uPk0Uk","executionInfo":{"status":"ok","timestamp":1703821079517,"user_tz":-540,"elapsed":19322,"user":{"displayName":"인공저지능","userId":"17810132175284132476"}},"outputId":"083aaf73-81e0-40aa-d0bb-39065dbd54b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"355EP0SdlPOL","executionInfo":{"status":"ok","timestamp":1703821092927,"user_tz":-540,"elapsed":314,"user":{"displayName":"인공저지능","userId":"17810132175284132476"}},"outputId":"236c5e56-f9ae-4af3-fc4d-2e8fb6767dd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["import os\n","import glob\n","import pandas as pd\n","import tensorflow as tf\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","from PIL import Image, ImageDraw\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.metrics import Precision, Recall\n","from tensorflow.keras.losses import BinaryCrossentropy\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"],"metadata":{"id":"rN0lhve_kWip"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_folder = 'data/test/dog/'\n","class_folders = os.listdir(base_folder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"nQHBksSukzL4","executionInfo":{"status":"error","timestamp":1703820045920,"user_tz":-540,"elapsed":5,"user":{"displayName":"인공저지능","userId":"17810132175284132476"}},"outputId":"51272119-bac1-4ff6-c8db-b460a50cbcd5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-6c3be3d36a9c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbase_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/test/dog/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclass_folders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/test/dog/'"]}]},{"cell_type":"code","source":["image_paths = []\n","json_paths = []\n","\n","for class_folder in class_folders:\n","    image_files = glob.glob(os.path.join(base_folder, class_folder, '*.jpg'))\n","    json_files = [file.replace('.jpg', '.json') for file in image_files]\n","\n","    image_paths.extend(image_files)\n","    json_paths.extend(json_files)\n","\n","image_paths = [path.replace('\\\\', '/') for path in image_paths]\n","json_paths = [path.replace('\\\\', '/') for path in json_paths]\n","\n","df = pd.DataFrame({\n","    'image_path': image_paths,\n","    'json_path': json_paths,\n","    'label': [path.split('/')[-2] for path in image_paths]\n","})"],"metadata":{"id":"oeQLxZ7PlqkA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_mask(image_path, json_path):\n","    try:\n","        image = Image.open(image_path)\n","        image = image.resize((256, 256))\n","\n","        with open(json_path, 'r', encoding='UTF-8') as file:\n","            data = json.load(file)\n","\n","        mask = Image.new('L', (256, 256), 0)\n","        draw = ImageDraw.Draw(mask)\n","\n","        for annotation in data['labelingInfo']:\n","            if 'polygon' in annotation:\n","                polygon = []\n","                for i in range(1, len(annotation['polygon']['location'][0]) // 2 + 1):\n","                    x_key = f'x{i}'\n","                    y_key = f'y{i}'\n","                    x = annotation['polygon']['location'][0].get(x_key)\n","                    y = annotation['polygon']['location'][0].get(y_key)\n","                    if x is not None and y is not None:\n","                        polygon.append((x, y))\n","\n","                if polygon:\n","                    draw.polygon(polygon, outline=1, fill=1)\n","        image = np.array(image, dtype=np.float32)\n","        mask = np.array(mask, dtype=np.float32)\n","        mask = np.expand_dims(mask, axis=-1)\n","\n","        return image, mask\n","    except Exception as e:\n","        empty_image = np.zeros((256, 256, 3), dtype=np.float32)\n","        empty_mask = np.zeros((256, 256, 1), dtype=np.float32)\n","        return empty_image, empty_mask"],"metadata":{"id":"snL8Ww6IlxFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tf_create_mask(image_path, json_path):\n","    [image, mask] = tf.numpy_function(create_mask, [image_path, json_path], [tf.float32, tf.float32])\n","    image.set_shape([256, 256, 3])\n","    mask.set_shape([256, 256, 1])\n","    return image, mask\n","\n","image_paths = df['image_path'].values\n","json_paths = df['json_path'].values\n","\n","dataset = tf.data.Dataset.from_tensor_slices((image_paths, json_paths))\n","dataset = dataset.map(tf_create_mask, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","dataset_size = len(image_paths)\n","train_size = int(0.8 * dataset_size)\n","val_size = dataset_size - train_size\n","\n","dataset = dataset.shuffle(buffer_size=dataset_size)\n","\n","train_dataset = dataset.take(train_size)\n","val_dataset = dataset.skip(train_size)\n","\n","train_dataset = train_dataset.batch(32)\n","val_dataset = val_dataset.batch(32)"],"metadata":{"id":"iFRRDEOplxKF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def unet_model(input_size=(256, 256, 3)):\n","    inputs = Input(input_size)\n","\n","    # 인코더\n","    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n","    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n","    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n","    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n","    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n","\n","    # 디코더\n","    up5 = UpSampling2D(size=(2, 2))(conv4)\n","    merge5 = concatenate([conv3, up5], axis=3)\n","    conv5 = Conv2D(256, 3, activation='relu', padding='same')(merge5)\n","    conv5 = Conv2D(256, 3, activation='relu', padding='same')(conv5)\n","\n","    up6 = UpSampling2D(size=(2, 2))(conv5)\n","    merge6 = concatenate([conv2, up6], axis=3)\n","    conv6 = Conv2D(128, 3, activation='relu', padding='same')(merge6)\n","    conv6 = Conv2D(128, 3, activation='relu', padding='same')(conv6)\n","\n","    up7 = UpSampling2D(size=(2, 2))(conv6)\n","    merge7 = concatenate([conv1, up7], axis=3)\n","    conv7 = Conv2D(64, 3, activation='relu', padding='same')(merge7)\n","    conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)\n","\n","    # 출력\n","    conv8 = Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n","\n","    model = Model(inputs=inputs, outputs=conv8)\n","\n","    return model\n","\n","unet = unet_model()\n","unet.compile(optimizer='adam',\n","             loss=BinaryCrossentropy(),\n","             metrics=['accuracy', Precision(), Recall()])"],"metadata":{"id":"0JwkDH1clxNF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["early_stopping = EarlyStopping(monitor='val_loss',\n","                               patience=10,\n","                               verbose=1,\n","                               mode='min',\n","                               restore_best_weights=True)\n","\n","checkpoint = ModelCheckpoint('model/dog_unet_model_{epoch:02d}.h5',\n","                             monitor='val_loss',\n","                             verbose=1,\n","                             save_best_only=False,\n","                             mode='min',\n","                             save_freq='epoch')"],"metadata":{"id":"qX6yh944lxPj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","saved_model = load_model(\"model/dog_unet_model_01.h5\")\n","\n","history = saved_model.fit(train_dataset,\n","                          validation_data=val_dataset,\n","                          epochs=20,\n","                          initial_epoch=2,\n","                          validation_steps=val_size // 32,\n","                          steps_per_epoch=train_size // 32,\n","                          callbacks=[checkpoint, early_stopping])"],"metadata":{"id":"oXkm0Jxnmk6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련 및 검증 손실 그래프\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# 훈련 및 검증 정확도 그래프\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"FHSwVUptlxUi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IgyjvsHYlxgi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6AscDIyXlxk-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3zj0-5iTlxnd"},"execution_count":null,"outputs":[]}]}